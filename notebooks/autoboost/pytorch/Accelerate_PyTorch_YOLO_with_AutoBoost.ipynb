{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c977e4a",
      "metadata": {
        "id": "3c977e4a"
      },
      "source": [
        "![nebullvm nebuly AI accelerate inference optimize DeepLearning](https://user-images.githubusercontent.com/38586138/201391643-a80407e5-2c28-409c-90c9-327795cd27e8.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6240f0ea",
      "metadata": {
        "id": "6240f0ea"
      },
      "source": [
        "# Accelerate PyTorch YOLO with AutoBoost\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cfcd562",
      "metadata": {
        "id": "6cfcd562"
      },
      "source": [
        "Hi and welcome ðŸ‘‹\n",
        "\n",
        "In this notebook we will discover how in just a few steps you can speed up the response time of deep learning model inference using the AutoBoost app from the open-source library nebullvm.\n",
        "\n",
        "With AutoBoost's latest API, you can speed up models up to 10 times without any loss of accuracy (option A), or accelerate them up to 20-30 times by setting a self-defined amount of accuracy/precision that you are willing to trade off to get even lower response time (option B). To accelerate your model, AutoBoost takes advantage of various optimization techniques such as deep learning compilers (in both option A and option B), quantization, half accuracy, and so on (option B).\n",
        "\n",
        "Let's jump to the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38171e92",
      "metadata": {},
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okgu97ThVwnH",
      "metadata": {
        "id": "okgu97ThVwnH"
      },
      "source": [
        "### Install AutoBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aljCHu14-H",
      "metadata": {
        "id": "48aljCHu14-H"
      },
      "source": [
        "Install AutoBoost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QFQh3BVr1-GO",
      "metadata": {
        "id": "QFQh3BVr1-GO"
      },
      "outputs": [],
      "source": [
        "!pip install autoboost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7a86b3",
      "metadata": {
        "id": "8a7a86b3"
      },
      "source": [
        "Install deep learning compilers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffbfa32",
      "metadata": {
        "id": "cffbfa32"
      },
      "outputs": [],
      "source": [
        "!python -m nebullvm.installers.auto_installer  --frameworks torch onnx --compilers all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62f5afa",
      "metadata": {
        "id": "e62f5afa"
      },
      "source": [
        "### Install and test YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38d727d",
      "metadata": {
        "id": "b38d727d"
      },
      "source": [
        "Let's install YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48f6a35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f48f6a35",
        "outputId": "5b06307a-9196-4e5e-a542-1254d6c94ce2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "! pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f49833",
      "metadata": {
        "id": "92f49833"
      },
      "source": [
        "We start by downloading the model from the Torch hub and running an initial inference on an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc46f67",
      "metadata": {
        "id": "2dc46f67"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "import types\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6637d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "7f41159d22fe4ce7b8e7789a92478242",
            "2ecf6a6cfad64af698a88479ba95005b",
            "e7a2646ac0cd4afba67823799147ce13",
            "fd77306783b84b489b90d072a44a27d8",
            "94a4bc5454074b5c900186a60a950d19",
            "682cafb37aa34c75961d61d2665a50b7",
            "5e71284dc02f4346b217732643c90b86",
            "881f619ee75547a49c6d48fd3140721c",
            "56a1b99b282a4a63a64f48347963a5ab",
            "a59557bb103e4a3b96062c60d539db35",
            "65786546f69b420b9ec8451c97338f30"
          ]
        },
        "id": "ead6637d",
        "outputId": "8d44d380-535d-446c-fcb0-bb55ba9e9f84"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
        "\n",
        "# Images\n",
        "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcteQ5tsWy1v",
      "metadata": {
        "id": "KcteQ5tsWy1v"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14415d7f",
      "metadata": {
        "id": "14415d7f"
      },
      "source": [
        "Let's now calculate the time required to run a prediction as an average over 100 tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01c7368",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e01c7368",
        "outputId": "f55d5847-0bf8-4b4c-e0ce-f9f1a4cc9fdc"
      },
      "outputs": [],
      "source": [
        "times = []\n",
        "for _ in range(100):\n",
        "    starting_time = time.time()\n",
        "    # Inference\n",
        "    results = model(imgs)\n",
        "    times.append((time.time()-starting_time)*1000)\n",
        "yolo_vanilla_time = sum(times) / len(times)\n",
        "print(f\"Average prediction time: {yolo_vanilla_time} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b773fc37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b773fc37",
        "outputId": "ce9eb31a-8cc5-4dc0-9153-837a2d86e1a9"
      },
      "outputs": [],
      "source": [
        "type(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea18697",
      "metadata": {
        "id": "bea18697"
      },
      "outputs": [],
      "source": [
        "#results.print()\n",
        "results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf19ef7e",
      "metadata": {
        "id": "bf19ef7e"
      },
      "source": [
        "Here we are! We got a good prediction, but it took a while :) Let's see if we are able to speed up the model a little bit without losing in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d07ab0",
      "metadata": {
        "id": "37d07ab0"
      },
      "source": [
        "## Optimization with AutoBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f9f650",
      "metadata": {
        "id": "74f9f650"
      },
      "outputs": [],
      "source": [
        "from autoboost import optimize_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147a42b9",
      "metadata": {
        "id": "147a42b9"
      },
      "source": [
        "First, we need to slightly modify YOLO's forward method. \n",
        "\n",
        "The last layer of the YOLOv5 implementation can create problems on certain hardware for some deep learning compilers that run on the AutoBoost core. Since AutoBoost aims to be hardware agnostic, we circumvent any potential obstacles by splitting the network body from the head (the last layer) and optimizing only the body."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cfaf99",
      "metadata": {
        "id": "56cfaf99"
      },
      "outputs": [],
      "source": [
        "core_model = copy.deepcopy(model.model.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9c8882",
      "metadata": {
        "id": "4f9c8882"
      },
      "outputs": [],
      "source": [
        "def _forward_once(self, x, profile=False, visualize=False):\n",
        "    y, dt = [], []  # outputs\n",
        "    for m in self.model:\n",
        "        if m.f != -1:  # if not from previous layer\n",
        "            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
        "        if profile:\n",
        "            self._profile_one_layer(m, x, dt)\n",
        "        x = m(x)  # run\n",
        "        y.append(x if m.i in self.save else None)  # save output\n",
        "        if visualize:\n",
        "            feature_visualization(x, m.type, m.i, save_dir=visualize)\n",
        "    self.last_y = y\n",
        "    return x\n",
        "core_model._forward_once = types.MethodType(_forward_once, core_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2197ca91",
      "metadata": {
        "id": "2197ca91"
      },
      "source": [
        "The reimplementation of the forward method is needed since we need to store the ys for giving to the head the right tensors as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0696b9",
      "metadata": {
        "id": "5b0696b9"
      },
      "outputs": [],
      "source": [
        "class CoreModelWrapper(torch.nn.Module):\n",
        "    def __init__(self, core_model, output_idxs):\n",
        "        super().__init__()\n",
        "        self.core = core_model\n",
        "        self.idxs = output_idxs\n",
        "        \n",
        "    def forward(self, *args, **kwargs):\n",
        "        x = self.core(*args, **kwargs)\n",
        "        return tuple(x if j == -1 else self.core.last_y[j] for j in self.idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeec4c1a",
      "metadata": {
        "id": "aeec4c1a"
      },
      "outputs": [],
      "source": [
        "list_of_layers = list(core_model.model.children())\n",
        "last_layer = list_of_layers.pop(-1)\n",
        "\n",
        "core_model.model = torch.nn.Sequential(*list_of_layers)\n",
        "core_wrapper = CoreModelWrapper(core_model, last_layer.f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332cbc38",
      "metadata": {
        "id": "332cbc38"
      },
      "source": [
        "Now we are ready for optimizing the body of YOLOv5 using the `AutoBoost` function `optimize_model`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1fc4d01",
      "metadata": {
        "id": "d1fc4d01"
      },
      "source": [
        "AutoBoost was built to be very easy to use. To optimize a model, you only need to specify the model, the batch size and input size for each input tensor, and a directory in which to save the optimized model. In the example, we chose the same directory in which this notebook runs.\n",
        "\n",
        "With the latest API, there are two ways to use AutoBoost:\n",
        "\n",
        "- Option A: Accelerate the model up to ~10 times without losing in performances (accuracy/precision/etc.)\n",
        "- Option B: Accelerate the model up to ~30 times with a pre-defined maximum loss in performances\n",
        "    \n",
        "To learn more about how to use AutoBoost, check out the <a href=\"https://github.com/nebuly-ai/nebullvm#get-started\" target=\"_blank\" style=\"text-decoration: none;\"> readme on GitHub </a>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb07403",
      "metadata": {
        "id": "ceb07403"
      },
      "source": [
        "In this example, we provide the code to run option B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c15b09",
      "metadata": {
        "id": "20c15b09"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcf6332",
      "metadata": {
        "id": "8fcf6332"
      },
      "outputs": [],
      "source": [
        "img_name = \"zidane.png\"\n",
        "Image.open(requests.get(imgs[0], stream=True).raw).save(img_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178a31f1",
      "metadata": {
        "id": "178a31f1"
      },
      "outputs": [],
      "source": [
        "def read_and_crop(im, original_model, img_size):\n",
        "    p  =  next(original_model.parameters())\n",
        "    im = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im)\n",
        "    max_y, max_x = im.size\n",
        "    ptr_x = np.random.choice(max_x-img_size[0])\n",
        "    ptr_y = np.random.choice(max_y-img_size[1])\n",
        "    im = np.array(im.crop((ptr_y, ptr_x, ptr_y + img_size[1], ptr_x + img_size[0])))\n",
        "    x = np.expand_dims(im, axis=0)\n",
        "    x = np.ascontiguousarray(np.array(x).transpose((0, 3, 1, 2)))  # stack and BHWC to BCHW\n",
        "    x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51757959",
      "metadata": {
        "id": "51757959"
      },
      "outputs": [],
      "source": [
        "input_data = [((read_and_crop(img_name, core_model, (384, 640)),), None) for _ in range(500)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01adfeb",
      "metadata": {
        "id": "c01adfeb"
      },
      "outputs": [],
      "source": [
        "model_optimized = optimize_model(\n",
        "    model=core_wrapper,\n",
        "    input_data=input_data,\n",
        "    optimization_time=\"unconstrained\",\n",
        "    metric_drop_ths=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e2866c",
      "metadata": {
        "id": "78e2866c"
      },
      "source": [
        "Now let's regroup together the optimized body and the head of YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff75e85f",
      "metadata": {
        "id": "ff75e85f"
      },
      "outputs": [],
      "source": [
        "class OptimizedYolo(torch.nn.Module):\n",
        "    def __init__(self, optimized_core, head_layer):\n",
        "        super().__init__()\n",
        "        self.core = optimized_core\n",
        "        self.head = head_layer\n",
        "    \n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = list(self.core(x)) # it's a tuple\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f973f2",
      "metadata": {
        "id": "c0f973f2"
      },
      "outputs": [],
      "source": [
        "final_core = OptimizedYolo(model_optimized, last_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e39d5b",
      "metadata": {
        "id": "82e39d5b"
      },
      "outputs": [],
      "source": [
        "model.model.model = final_core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe285d08",
      "metadata": {
        "id": "fe285d08"
      },
      "source": [
        "Finally we can check the speedup. Let's calculate the time required to run a prediction as an average over 100 tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ee7a50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ee7a50",
        "outputId": "bdeda432-d466-4500-e35c-e3729c35e1ba"
      },
      "outputs": [],
      "source": [
        "times = []\n",
        "for _ in range(100):\n",
        "    st = time.time()\n",
        "    results = model(imgs)\n",
        "    times.append((time.time() - st)*1000)\n",
        "yolo_optimized_time = sum(times) / len(times)\n",
        "print(f\"Average prediction time: {yolo_optimized_time} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72a0cc9",
      "metadata": {
        "id": "b72a0cc9"
      },
      "outputs": [],
      "source": [
        "results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50807de",
      "metadata": {
        "id": "d50807de"
      },
      "source": [
        "What an amazing result, right?!? Stay tuned for more cool content from the Nebuly team :) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c90ff6e5",
      "metadata": {},
      "source": [
        "<center> \n",
        "    <a href=\"https://discord.com/invite/RbeQMu886J\" target=\"_blank\" style=\"text-decoration: none;\"> Join the community </a> |\n",
        "    <a href=\"https://nebuly.gitbook.io/nebuly/welcome/questions-and-contributions\" target=\"_blank\" style=\"text-decoration: none;\"> Contribute to the library </a>\n",
        "</center>\n",
        "\n",
        "<center> \n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#how-it-works\" target=\"_blank\" style=\"text-decoration: none;\"> How nebullvm works </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#documentation\" target=\"_blank\" style=\"text-decoration: none;\"> Documentation </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#api-quick-view\" target=\"_blank\" style=\"text-decoration: none;\"> API quick view </a> \n",
        "</center>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ecf6a6cfad64af698a88479ba95005b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682cafb37aa34c75961d61d2665a50b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e71284dc02f4346b217732643c90b86",
            "value": "100%"
          }
        },
        "56a1b99b282a4a63a64f48347963a5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e71284dc02f4346b217732643c90b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65786546f69b420b9ec8451c97338f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682cafb37aa34c75961d61d2665a50b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f41159d22fe4ce7b8e7789a92478242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ecf6a6cfad64af698a88479ba95005b",
              "IPY_MODEL_e7a2646ac0cd4afba67823799147ce13",
              "IPY_MODEL_fd77306783b84b489b90d072a44a27d8"
            ],
            "layout": "IPY_MODEL_94a4bc5454074b5c900186a60a950d19"
          }
        },
        "881f619ee75547a49c6d48fd3140721c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a4bc5454074b5c900186a60a950d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59557bb103e4a3b96062c60d539db35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a2646ac0cd4afba67823799147ce13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881f619ee75547a49c6d48fd3140721c",
            "max": 14808437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56a1b99b282a4a63a64f48347963a5ab",
            "value": 14808437
          }
        },
        "fd77306783b84b489b90d072a44a27d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59557bb103e4a3b96062c60d539db35",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65786546f69b420b9ec8451c97338f30",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 24.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
